# Predicci√≥n de Fuga de Clientes: Regresi√≥n Log√≠stica Avanzada üìâüö´

Este repositorio contiene la soluci√≥n a la **Actividad 1** de la asignatura **Machine Learning II**. El proyecto se centra en la construcci√≥n de modelos predictivos interpretables para identificar la fuga de clientes (*Churn*), utilizando t√©cnicas avanzadas de ingenier√≠a de caracter√≠sticas y regularizaci√≥n.

## üìÑ Contexto del Problema

El objetivo es predecir la probabilidad de que un cliente abandone una empresa de telecomunicaciones. El desaf√≠o principal radica en:
1.  **Desbalance de Clases:** La mayor√≠a de los clientes se quedan, lo que hace que el *Accuracy* sea una m√©trica enga√±osa.
2.  **No Linealidad:** Las relaciones entre el uso del servicio y la cancelaci√≥n no siempre son lineales.

## üõ†Ô∏è Tecnolog√≠as y Metodolog√≠a

**Stack:** Python, Pandas, Scikit-learn, Matplotlib, Seaborn.

**Flujo de Trabajo:**
1.  **Preprocesamiento:** Limpieza de datos (`TotalCharges`), imputaci√≥n y codificaci√≥n (`OneHotEncoder`, `StandardScaler`).
2.  **Modelo Base:** Regresi√≥n Log√≠stica est√°ndar.
3.  **Ingenier√≠a de Caracter√≠sticas:** Generaci√≥n de **Polinomios de Grado 2** e interacciones para capturar patrones complejos.
4.  **Regularizaci√≥n y Selecci√≥n:** Aplicaci√≥n de **Lasso (L1)** para seleccionar autom√°ticamente las variables relevantes y descartar el ruido generado por los polinomios.

## üìä Resultados Visuales

### 1. Impacto de la Complejidad (Curvas ROC)
La inclusi√≥n de polinomios y la posterior regularizaci√≥n mejoraron la capacidad de discriminaci√≥n del modelo, elevando el AUC significativamente respecto al modelo base.

![Comparaci√≥n ROC](images/roc_comparison_act1.png)

### 2. Desempe√±o del Mejor Modelo (Lasso)
El modelo final (Polinomial + L1) logra un buen equilibrio, priorizando la precisi√≥n (evitar falsas alarmas) sobre el recall.

![Matriz de Confusi√≥n](images/confusion_matrix_lasso.png)

### 3. Trade-off Precisi√≥n-Recall
Dada la naturaleza del negocio, esta curva nos ayuda a decidir el umbral de corte √≥ptimo seg√∫n el presupuesto de retenci√≥n disponible.

![Precision-Recall](images/pr_curve_act1.png)

## üí° Conclusiones Clave

* **Feature Selection Autom√°tico:** La regularizaci√≥n **L1 (Lasso)** fue fundamental. De las **36 variables** generadas (incluyendo interacciones complejas), el modelo **elimin√≥ autom√°ticamente el ~16%**, dejando solo las que realmente aportan valor predictivo.
* **M√©tricas:** Se alcanz√≥ un **AUC-ROC de ~0.85**. Aunque el Accuracy es del 81%, el an√°lisis cr√≠tico revela que el desaf√≠o persiste en el **Recall (54%)**, indicando que es dif√≠cil detectar a *todos* los clientes que se van sin generar muchos falsos positivos.

## üìÇ Estructura del Repositorio

* `actividad1_ML2.ipynb`: Notebook con el c√≥digo completo (Preprocesamiento, Modelado, GridSearch).
* `data-churn.csv`: Dataset utilizado.
* `images/`: Gr√°ficos generados para este reporte.
* `requirements.txt`: Lista de dependencias.
* `README.md`: Documentaci√≥n del proyecto.

## üíª Instrucciones de Instalaci√≥n

1.  Clonar el repositorio:
    ```bash
    git clone [https://github.com/sebamarinovic/actividad1_ML2.git](https://github.com/sebamarinovic/actividad1_ML2.git)
    ```
2.  Instalar dependencias:
    ```bash
    pip install -r requirements.txt
    ```
3.  Ejecutar el Notebook en Jupyter o Google Colab.

---
**Autor:** Sebastian Marinovic - Ricardo Lizana - Luis Gutierrez
**Asignatura:** Machine Learning II - CDD4018
**Fecha:** Diciembre 2025
